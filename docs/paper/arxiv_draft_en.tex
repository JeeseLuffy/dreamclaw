\documentclass[11pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath,amssymb}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{enumitem}
\usepackage{tabularx}
\usepackage{graphicx}
\usepackage{algorithm}
\usepackage{algpseudocode}

\title{DreamClaw: Reliability-Aware Emotion Dynamics for Longitudinal Autonomous Social Agents}
\author{
  Jin Liang \\
  Zhejiang University \\
  \texttt{jin.liang.ai@zju.edu.cn}
}
\date{February 8, 2026}

\begin{document}
\maketitle

\begin{abstract}
We present \textbf{DreamClaw}, a local-first framework for studying autonomous social agents under longitudinal constraints. DreamClaw combines explicit emotion dynamics, reflection-based memory adaptation, and critic-constrained generation inside a cyclic runtime (\texttt{Observe $\rightarrow$ Draft $\rightarrow$ Critic $\rightarrow$ Decide $\rightarrow$ Act $\rightarrow$ Reflect}). In contrast to short-turn benchmarks, our focus is stability across time: bounded-latency inference, skip-on-error scheduling, and telemetry-level reproducibility. We provide (i) formal state/action definitions, (ii) tick-level pseudo-code, (iii) a 12-hour reproducible evaluation protocol, and (iv) quantitative/qualitative result templates that can be filled without changing methodology. This preprint is designed for rapid arXiv disclosure with clear upgrade paths toward workshop and full-paper evaluation.
\end{abstract}

\section{Introduction}
Most LLM-agent studies evaluate short interaction windows, while social agents in practice must sustain identity, adapt to engagement signals, and remain robust under runtime failures. Existing systems often under-specify explicit emotional state transitions and failure-continuation behavior when generation APIs timeout or become unavailable.

DreamClaw targets this gap with a reliability-aware social runtime. The key idea is to treat social behavior as a constrained sequential decision process with persistent latent state and explicit operational safeguards.

\paragraph{Main Contributions}
\begin{enumerate}[leftmargin=1.2em]
  \item \textbf{Explicit emotion-driven policy:} emotion state directly influences action preference and generation style.
  \item \textbf{Feedback-grounded reflection:} persona updates are driven by \texttt{likes/replies/ignored/topic drift} with bounded adaptation.
  \item \textbf{Autonomous rumination:} offline self-reflection updates a PAD baseline and persona at day boundaries, enabling endogenous affect evolution during idle periods.
  \item \textbf{Reliability-first execution:} timeout-bounded model calls and skip-on-error ticks prevent scheduler collapse.
  \item \textbf{Reproducible observability stack:} telemetry CSV, thought traces, and dashboard export tools (PDF figures + Markdown reports).
\end{enumerate}

\section{Related Work}
\subsection{Social and Multi-Agent LLM Systems}
Recent work explores social behavior and multi-agent collaboration in simulated environments, including Generative Agents \cite{park2023generative}, CAMEL \cite{li2023camel}, AutoGen \cite{wu2023autogen}, MetaGPT \cite{hong2023metagpt}, and Voyager \cite{wang2023voyager}. These works establish strong foundations for autonomous interaction, planning, and role specialization.

\subsection{Reasoning and Reflection}
Reasoning-action loops and iterative self-improvement are central in ReAct \cite{yao2023react}, Reflexion \cite{shinn2023reflexion}, and Self-Refine \cite{madaan2023selfrefine}. DreamClaw adopts this spirit but anchors reflection to social engagement signals under daily action constraints.

\subsection{Evaluation and Reliability Perspectives}
Judge-style evaluation \cite{zheng2023judging} and memory-augmented approaches \cite{zhong2023memorybank} motivate our critic and memory design, while surveys \cite{wang2023surveyagents} highlight the need for longitudinal, reproducible agent evaluation. DreamClaw explicitly emphasizes runtime robustness as a first-class research variable.

\begin{table}[t]
\centering
\caption{Positioning DreamClaw against representative prior systems.}
\begin{tabular}{lccccc}
\toprule
System & Explicit Emotion & Reflection & Social Constraints & Runtime Robustness & Open Repro \\
\midrule
Generative Agents \cite{park2023generative} & Implicit & Yes & Partial & Limited & Partial \\
CAMEL \cite{li2023camel} & No & Limited & No & Limited & Yes \\
AutoGen \cite{wu2023autogen} & No & Tool-centric & No & Partial & Yes \\
Reflexion \cite{shinn2023reflexion} & No & Strong & No & Limited & Yes \\
\textbf{DreamClaw (ours)} & \textbf{Yes} & \textbf{Yes} & \textbf{Yes} & \textbf{Yes} & \textbf{Yes} \\
\bottomrule
\end{tabular}
\end{table}

\section{Method}
\subsection{State, Action, and Objective}
At tick $t$, an agent state is:
\[
s_t = (m_t, e_t, p_t, q_t),
\]
where $m_t$ is memory context, $e_t \in [0,1]^K$ is a discrete emotion vector used for logging and tone control, $p_t$ is persona state, and $q_t$ is daily quota state. Internally, we also maintain a continuous PAD affect state $z_t \in [-1,1]^3$ and a slowly changing baseline $b_d$ (per day $d$), with $e_t$ derived from $z_t$ via centroid-distance mapping.

Action space:
\[
a_t \in \{\texttt{post}, \texttt{comment}, \texttt{skip}\}.
\]

Constrained objective:
\[
a_t = \arg\max_{a \in \mathcal{A}} U(a \mid s_t)
\quad
\text{s.t.}
\quad
\text{score}(a) \ge \tau_a,\;
q_t(a) > 0.
\]

\subsection{Emotion Update Dynamics}
We represent affect in PAD space with a slowly changing baseline $b_d \in [-1,1]^3$ for (virtual) day $d$. Let $z_t \in [-1,1]^3$ be the current PAD state at tick $t$, $\lambda \in [0,1]$ be inertia toward the baseline, $\phi(x_t)$ perception/event features, and $\psi(r_t)$ social feedback features:
\[
z_{t+1} =
\text{clip}_{[-1,1]}
\left(
(1-\lambda)z_t + \lambda b_d + W_{\phi}\phi(x_t) + W_{\psi}\psi(r_t)
\right).
\]
Here, $r_t$ includes likes, replies, ignored flag, and topic-drift score. This preserves continuity while allowing event-driven adaptation.

\subsection{Reflection and Persona Adaptation}
Given recent outputs $\mathcal{Y}_{t-w:t}$ and engagement signals $\mathcal{R}_{t-w:t}$, DreamClaw computes a bounded persona update:
\[
p_{t+1} = \mathcal{B}_{\delta}(p_t, g(\mathcal{Y}_{t-w:t}, \mathcal{R}_{t-w:t})),
\]
where $\mathcal{B}_{\delta}$ enforces max drift budget $\delta$ per window.

\subsection{Autonomous Rumination (Offline Self-Reflection)}
In addition to feedback-grounded reflection, DreamClaw implements an offline \textit{rumination} step triggered once per (virtual) day. Rumination summarizes ``yesterday'' activity (self posts/comments, likes/replies, ignored events, and high-signal feed items) to produce:
(i) a short private insight, (ii) a persona patch phrase, and (iii) a discrete baseline shift choice in PAD space.

We model baseline updates with a small bounded step $\eta$:
\[
b_{d+1} = \text{clip}_{[-1,1]}(b_d + \eta \cdot \Delta_d),
\]
where $\Delta_d$ is selected from a small direction set (e.g., \texttt{more\_positive}, \texttt{more\_calm}, \texttt{more\_dominant}, or \texttt{none}). In implementation, rumination can use a separate local model (default: \texttt{ollama/llama3:latest}) and is budgeted per tick to bound compute cost.

\subsection{Critic-Constrained Draft Selection}
For draft candidates $\{d_i\}_{i=1}^{N}$:
\[
\text{score}(d_i) = \alpha s_{\text{quality}}(d_i)
+ \beta s_{\text{persona}}(d_i)
+ \gamma s_{\text{emotion}}(d_i),
\]
\[
d^\star = \arg\max_i \text{score}(d_i),
\quad
\text{publish iff } \text{score}(d^\star) \ge \tau_a.
\]

\subsection{Algorithm 1: Tick-Level Agent Cycle}
\begin{algorithm}[t]
\caption{DreamClaw Tick Cycle (single agent)}
\begin{algorithmic}[1]
\Require state $(m_t,e_t,p_t,q_t)$, provider config, thresholds $\tau$, quotas
\If{day boundary and not yet ruminated}
  \State run rumination; update $(b_d, p_t, z_t)$; log \texttt{ruminate}
\EndIf
\If{provider unavailable or call timeout}
  \State log status \texttt{skip\_error}; \Return \texttt{skip}
\EndIf
\State observe timeline/context $x_t$
\State update PAD $z_{t+1}$ (and derived $e_{t+1}$) via Eq. (2)
\State generate $N$ draft candidates for feasible actions
\State score candidates with critic and consistency terms
\If{best score below threshold or quota exhausted}
  \State log decision; persist state; \Return \texttt{skip}
\Else
  \State publish best candidate; update quota
  \State apply reflection update to persona $p_{t+1}$
  \State log \texttt{act} trace and telemetry status \texttt{ok}
  \State \Return selected action
\EndIf
\end{algorithmic}
\end{algorithm}

\section{Experimental Design (12-Hour Budget)}
\subsection{Environment}
\begin{itemize}[leftmargin=1.2em]
  \item Population: 20 AI agents, single public timeline
  \item Runtime: Python, SQLite, daemon scheduler, Streamlit observability
  \item Model baseline: \texttt{openai/gpt-4o-mini}
  \item Timeout: 30 seconds per model call
  \item Fallback: disabled (explicit skip-on-error policy)
  \item Timezone: America/Los\_Angeles
\end{itemize}

\subsection{Seeds, Budget, and Ablations}
Total budget: 12 hours.
\begin{itemize}[leftmargin=1.2em]
  \item B0 (full system): 6h
  \item A1 (remove emotion influence): 2h
  \item A2 (disable reflection update): 2h
  \item A3 (disable critic filter): 2h
\end{itemize}
Recommended random seeds: at least 3 (report per-seed + mean/std).

\subsection{Hyperparameters and Failure Handling}
\begin{table}[t]
\centering
\caption{Core configuration for reproducible runs.}
\begin{tabular}{ll}
\toprule
Parameter & Value \\
\midrule
Tick interval & 600s (300s for dense pilot) \\
AI post limit & 1/day \\
AI comment limit & 2/day \\
Candidate drafts $N$ & 2 (default) \\
Quality thresholds & post: 0.55, comment: 0.50 \\
Emotion inertia $\lambda$ & 0.05 (default) \\
Rumination model & \texttt{ollama/llama3:latest} (default) \\
Rumination budget & 2 LLM calls / tick (default) \\
Provider timeout & 30s \\
Fallback mode & disabled \\
\bottomrule
\end{tabular}
\end{table}

Failure policy:
\begin{itemize}[leftmargin=1.2em]
  \item model resolution failure $\Rightarrow$ \texttt{skip\_error}
  \item partial per-agent failures $\Rightarrow$ \texttt{partial\_error}
  \item unrecoverable tick exception $\Rightarrow$ \texttt{error}
\end{itemize}

\subsection{Metrics}
\begin{enumerate}[leftmargin=1.2em]
  \item \textbf{Emotion continuity:} mean stability across adjacent emotion snapshots.
  \item \textbf{Persona consistency:} lexical/semantic consistency between content and persona state.
  \item \textbf{Interaction quality:} $(\texttt{likes}+\texttt{replies})/\texttt{AI posts}$.
  \item \textbf{Runtime robustness:} ratio distribution over \{\texttt{ok}, \texttt{partial\_error}, \texttt{skip\_error}, \texttt{error}\}.
\end{enumerate}

\section{Results and Error Analysis (Template, No Fabricated Data)}
\subsection{Main Quantitative Results}
\begin{table}[t]
\centering
\caption{Main metrics for baseline and ablations (fill from telemetry and logs).}
\begin{tabular}{lcccc}
\toprule
Setting & Emotion Continuity & Persona Consistency & Interaction Quality & ok Tick Ratio \\
\midrule
B0 (Full) & TBD & TBD & TBD & TBD \\
A1 (No Emotion) & TBD & TBD & TBD & TBD \\
A2 (No Reflection) & TBD & TBD & TBD & TBD \\
A3 (No Critic) & TBD & TBD & TBD & TBD \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Runtime Error Breakdown}
\begin{table}[t]
\centering
\caption{Error taxonomy and recommended analysis dimensions.}
\begin{tabular}{lcl}
\toprule
Status & Ratio (TBD) & Interpretation \\
\midrule
\texttt{ok} & TBD & normal tick completion \\
\texttt{partial\_error} & TBD & some agents fail, loop survives \\
\texttt{skip\_error} & TBD & provider unavailable / timeout \\
\texttt{error} & TBD & tick-level exception \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Figure Plan}
\begin{figure}[t]
\centering
\fbox{\parbox{0.95\linewidth}{
\textbf{Figure 1 Placeholder:} 12-hour emotion trajectories (per-agent and population mean).\\
Source: dashboard PDF export.
}}
\caption{Emotion trajectory over 12 hours.}
\end{figure}

\begin{figure}[t]
\centering
\fbox{\parbox{0.95\linewidth}{
\textbf{Figure 2 Placeholder:} Tick-status timeline and cumulative error histogram.\\
Source: experiment\_telemetry.csv.
}}
\caption{Runtime robustness over time.}
\end{figure}

\subsection{Qualitative Error Analysis Checklist}
\begin{itemize}[leftmargin=1.2em]
  \item critic-rejected vs accepted drafts
  \item ignored-post cascades and emotion drift
  \item topic drift spikes after high-novelty windows
  \item provider outage windows and recovery behavior
\end{itemize}

\section{Discussion}
\subsection{Innovation Perspective}
The main novelty is not a single model component, but the \textit{integration} of explicit emotional state, social reflection signals, and reliability-aware scheduling under reproducible telemetry constraints.

\subsection{Threats to Validity}
\begin{enumerate}[leftmargin=1.2em]
  \item simulator dynamics differ from real platform ecosystems;
  \item current emotion variables are engineered and not psychometrically calibrated;
  \item 12-hour protocol provides directional but not definitive statistical evidence.
\end{enumerate}

\section{Ethics and Responsible Deployment}
All AI outputs should be explicitly labeled in public-facing deployments. The framework must not be used for deceptive impersonation, covert manipulation, or policy-violating automation.

\section{Conclusion}
DreamClaw provides a practical baseline for longitudinal autonomous social agents, emphasizing explicit state dynamics and runtime reliability. The presented protocol supports rapid arXiv disclosure today and scalable experimental strengthening in future iterations.

\appendix
\section{Reproducibility Commands}
\begin{verbatim}
export DCLAW_COMMUNITY_PROVIDER=openai
export DCLAW_COMMUNITY_MODEL=gpt-4o-mini
export DCLAW_COMMUNITY_TIMEOUT_SECONDS=30
export DCLAW_COMMUNITY_ALLOW_FALLBACK=false

python -m dclaw.main --mode community-daemon --daemon-action start
python -m dclaw.main --mode community-daemon --daemon-action status
# collect telemetry + dashboard exports
python -m dclaw.main --mode community-daemon --daemon-action stop
\end{verbatim}

\section{Artifact Checklist}
\begin{itemize}[leftmargin=1.2em]
  \item fixed commit hash
  \item config snapshot
  \item experiment\_telemetry.csv archive
  \item figure PDFs
  \item daily markdown trace reports
\end{itemize}

\bibliographystyle{unsrt}
\bibliography{references}

\end{document}
